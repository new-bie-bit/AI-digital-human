# AI-digital-human
本项目旨在生成高真实度的数字人形象，并通过虚幻引擎进行语音与动作驱动，实现交互式展示与表达。我们成功实现了数字人与大模型语言的交流任务，将大语言模型的智能输出“具象化”为一个具有人格特征的虚拟形象。
好的，根据您提供的文档内容，我为您总结了一个GitHub README.md的介绍，旨在清晰、简洁地展示您的项目。

---

# 基于大模型语言的数字人交互系统

## 🚀 项目概述

本项目旨在**生成高真实度的数字人形象，并通过虚幻引擎进行语音与动作驱动，实现交互式展示与表达**。我们成功实现了数字人与大模型语言的交流任务，将大语言模型的智能输出“具象化”为一个具有人格特征的虚拟形象。

本项目不仅完成了从数字人生成到语音驱动的全流程，也探索了数字人作为大模型交互载体的可行路径。

**核心目标：**
*   **项目名称:** 数字人生成与交互式驱动系统
*   **项目目标:** 生成高真实度的数字人形象，并通过虚幻引擎进行语音与动作驱动，实现交互式展示与表达。
*   **展示内容:** 头部与全身建模、语音表演、口型同步、身体动作、对话交互等。

## ✨ 主要功能与特性

*   **高精度数字人创建:** 利用MetaHuman Creator生成逼真的数字人模型。
*   **虚幻引擎驱动:** 在Unreal Engine 5中实现模型导入、绑定、实时渲染与驱动。
*   **智能语音与口型同步:** 通过MetaHuman SDK和蓝图实现文本转语音（TTS）及精确的口型动画同步。
*   **大模型集成:** 利用VaRest插件调用外部AI接口（如豆包大模型），实现基于大模型的智能对话交互。
*   **丰富的动作与手势:** 设计并调试了多种讲解类手势，如开场招呼、强调重点、自问自答、结束语收尾等，增强数字人表达的自然度。
*   **交互逻辑开发:** 实现数字人与用户的多轮对话交互。

## 🛠️ 所使用工具与技术

| 类型       | 工具名称           | 技术细节与原理                                                              |
| :--------- | :----------------- | :-------------------------------------------------------------------------- |
| 数字人创建 | MetaHuman Creator  | 云端高精度数字人创建工具                                                    |
| 驱动引擎   | Unreal Engine 5    | 支持实时渲染与MetaHuman整合                                                 |
| 音频驱动   | MetaHuman SDK、蓝图 | 实现口型驱动与声音合成 (TTS、ATLAudio to Lipsync)                           |
| 大模型驱动 | VaRest             | 实现大模型（豆包）请求，VaRest插件调用外部AI接口                            |

## ⚙️ 实现流程

1.  **数字人创建:** 使用 MetaHuman Creator。
2.  **模型导入与绑定:** 在 Unreal Engine 5 中完成。
3.  **驱动系统集成:** 实现文本对话驱动与口型同步。
4.  **交互逻辑开发:** 构建数字人与用户的交互逻辑。
5.  **视频录制与渲染:** 最终成果的展示。

## 💡 展望与未来工作

*   **增强实时性与互动性:** 结合实时语音识别（ASR）与语音合成（TTS），实现“听说同步”的实时对话体验，打造更加自然的数字人互动场景。（注：ASR部分原计划使用AzSpeech，但遇到注册和闪退问题，暂未完美完成。）
*   **丰富情绪表达与动作控制:** 引入情绪识别机制与面部/身体动画驱动算法，使数字人具备更具感染力的表情与动作表现。
*   **接入更强大的语言模型:** 结合多模态大模型（如GPT-4o、Claude等），让数字人不仅能“说话”更能“理解”和“思考”。
*   **拓展应用场景:** 尝试将数字人应用于教育讲解、数字客服、文旅导览、虚拟主持人等多种实际应用中，实现技术价值的真正落地。

## 🧑‍💻 贡献者

本项目由以下成员共同完成：

